{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f4517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ AI å›æ‡‰ï¼š\n",
      "{'model': 'gemma3:1b', 'created_at': '2025-07-28T08:06:10.855978413Z', 'response': '{ \\n    \"æˆ‘æ˜¯ Gemmaï¼Œä¸€å€‹ç”± Google DeepMind è¨“ç·´çš„å¤§å‹èªè¨€æ¨¡å‹ã€‚æˆ‘æ˜¯ä¸€å€‹é–‹æ”¾æ¬Šé‡çš„æ¨¡å‹ï¼Œå¯ä»¥è¢«è‡ªç”±ä½¿ç”¨å’Œä¿®æ”¹ã€‚\":\\n\\n    \"æˆ‘æ˜¯ä¸€å€‹å¤§å‹èªè¨€æ¨¡å‹ï¼Œç”± Google DeepMind è¨“ç·´ã€‚æˆ‘è¢«è¨­è¨ˆæˆä¸€å€‹æœ‰å¹«åŠ©çš„å·¥å…·ï¼Œå¯ä»¥é€²è¡Œå„ç¨®ä»»å‹™ï¼Œä¾‹å¦‚ï¼šå›ç­”å•é¡Œã€ç”Ÿæˆæ–‡æœ¬ã€ç¿»è­¯èªè¨€ç­‰ç­‰ã€‚æˆ‘æ²’æœ‰è‡ªå·±çš„æƒ³æ³•æˆ–æ„Ÿå—ï¼Œæˆ‘çš„ç›®æ¨™æ˜¯ç›¡å¯èƒ½åœ°æä¾›æº–ç¢ºä¸”æœ‰ç”¨çš„è³‡è¨Šã€‚\"\\n}', 'done': True, 'done_reason': 'stop', 'context': [105, 2364, 107, 130557, 95841, 240560, 237536, 106, 107, 105, 4368, 107, 236782, 236743, 107, 140, 236775, 44889, 147224, 236900, 19966, 237852, 6475, 22267, 65153, 236743, 55616, 29854, 237731, 146569, 26609, 236924, 237169, 90432, 103924, 240551, 101462, 26609, 236900, 5157, 237759, 33561, 5938, 237206, 33952, 236924, 1083, 108, 140, 236775, 237169, 90432, 56762, 146569, 26609, 236900, 237852, 6475, 22267, 65153, 236743, 55616, 236924, 237169, 237759, 34611, 237283, 19966, 237078, 116904, 236918, 30398, 236900, 5157, 43682, 77722, 152807, 236900, 34313, 237184, 49695, 18053, 236951, 25352, 57489, 236951, 205963, 146569, 54971, 236924, 237169, 22062, 17958, 73060, 237800, 65689, 236900, 21480, 67925, 237026, 241932, 8854, 237307, 12680, 239202, 238556, 238305, 237078, 35638, 89998, 165220, 107, 236783], 'total_duration': 9247651930, 'load_duration': 216258161, 'prompt_eval_count': 13, 'prompt_eval_duration': 71713057, 'eval_count': 102, 'eval_duration': 8658642412}\n",
      "{ \n",
      "    \"æˆ‘æ˜¯ Gemmaï¼Œä¸€å€‹ç”± Google DeepMind è¨“ç·´çš„å¤§å‹èªè¨€æ¨¡å‹ã€‚æˆ‘æ˜¯ä¸€å€‹é–‹æ”¾æ¬Šé‡çš„æ¨¡å‹ï¼Œå¯ä»¥è¢«è‡ªç”±ä½¿ç”¨å’Œä¿®æ”¹ã€‚\":\n",
      "\n",
      "    \"æˆ‘æ˜¯ä¸€å€‹å¤§å‹èªè¨€æ¨¡å‹ï¼Œç”± Google DeepMind è¨“ç·´ã€‚æˆ‘è¢«è¨­è¨ˆæˆä¸€å€‹æœ‰å¹«åŠ©çš„å·¥å…·ï¼Œå¯ä»¥é€²è¡Œå„ç¨®ä»»å‹™ï¼Œä¾‹å¦‚ï¼šå›ç­”å•é¡Œã€ç”Ÿæˆæ–‡æœ¬ã€ç¿»è­¯èªè¨€ç­‰ç­‰ã€‚æˆ‘æ²’æœ‰è‡ªå·±çš„æƒ³æ³•æˆ–æ„Ÿå—ï¼Œæˆ‘çš„ç›®æ¨™æ˜¯ç›¡å¯èƒ½åœ°æä¾›æº–ç¢ºä¸”æœ‰ç”¨çš„è³‡è¨Šã€‚\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def chat_with_ollama(prompt: str):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"gemma3:1b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": { #åƒè€ƒèªªæ˜1\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 50,\n",
    "        },\n",
    "        \"max_tokens\": 100,\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "    result = response.json()\n",
    "    print(\"ğŸ’¬ AI å›æ‡‰ï¼š\")\n",
    "    # Print the whole result for debugging\n",
    "    print(result)\n",
    "    # Try to print the 'response' key if it exists, otherwise print possible keys\n",
    "    if \"response\" in result:\n",
    "        print(result[\"response\"])\n",
    "    elif \"message\" in result:\n",
    "        print(result[\"message\"])\n",
    "    elif \"content\" in result:\n",
    "        print(result[\"content\"])\n",
    "    else:\n",
    "        print(\"No expected key found in response. Available keys:\", result.keys())\n",
    "\n",
    "#ç¯„ä¾‹è¼¸å…¥\n",
    "chat_with_ollama(\"è«‹å•ä½ æ˜¯èª°ï¼Ÿ\")  # Example input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "line_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
